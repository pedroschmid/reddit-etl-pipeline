
# ğŸ“Š Reddit ETL Pipeline

## ğŸ¯ Objective

This project provides a data pipeline solution to extract, transform, and load (ETL) Reddit data into a Redshift data warehouse. The pipeline leverages a combination of tools and services including Apache Airflow, Celery, PostgreSQL, Amazon S3, AWS Glue, Amazon Athena, and Amazon Redshift.

With this project, you will learn:

- ğŸŒ¬ï¸ **Apache Airflow** with **Celery** and **PostgreSQL**
- ğŸ³ **Docker**
- ğŸ“ Using the **Reddit API**
- ğŸ› ï¸ **AWS Glue**
- ğŸ—„ï¸ **AWS S3**
- ğŸ“Š **AWS Athena**
- ğŸ¢ **Redshift Data Warehousing**

---

## ğŸ—ï¸ Architecture

The architecture of this pipeline is designed as follows:

![Project Architecture](images/architecture.png)

---

## âš™ï¸ Prerequisites

To run this project locally, you will need the following:

- ğŸ Python 3.9 or higher
- ğŸ³ Docker and Docker Compose
- ğŸŒ Terraform
- â˜ï¸ AWS CLI configured with valid credentials
- ğŸ”‘ Reddit API credentials (Client ID, Client Secret, Access Token)

---

## ğŸš€ How to Run the Project Locally

### 1. ğŸ“ Clone the repository

```bash
git clone https://github.com/your-username/reddit-etl-pipeline.git
cd reddit-etl-pipeline
```

### 2. ğŸ Set up a virtual environment

It's recommended to use a virtual environment to manage dependencies:

```bash
python -m venv venv
source venv/bin/activate  # On Windows use `venv\Scripts\activate`
```

### 3. ğŸ“¦ Install the required Python dependencies

Install the dependencies listed in `requirements.txt`:

```bash
pip install -r requirements.txt
```

### 4. ğŸ”§ Set up environment variables

You need to configure your environment variables for Reddit API and AWS. Copy the provided `.env.example` to `.env` and fill in your credentials:

Edit the `.env` file and include your Reddit API keys, AWS access keys, and other necessary details.

### 5. ğŸƒâ€â™‚ï¸ Run Airflow with Docker Compose

Start the services with Docker Compose:

```bash
docker-compose up --build
```

Access the Airflow UI at `http://localhost:8080` and trigger the `reddit_dag`.

---

## ğŸŒ Terraform Setup

The infrastructure for this project is provisioned using Terraform.

### 1. ğŸ“ Configure `terraform.tfvars`

Edit the `terraform.tfvars` file with your AWS credentials and other necessary variables.

### 2. âš™ï¸ Initialize Terraform

```bash
terraform init
```

### 3. ğŸ” Plan and Apply

To preview the infrastructure changes:

```bash
terraform plan
```

To apply the infrastructure changes:

```bash
terraform apply
```

This will provision all necessary AWS services such as S3 buckets, AWS Glue, Athena, and Redshift.

---

## ğŸ¤ Contributing

Feel free to submit pull requests or raise issues on GitHub. Contributions are welcome!

---

## ğŸ“ License

This project is licensed under the MIT License. See the [LICENSE](LICENSE) file for more details.